{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NnoCuhMZylQO"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/u/0/uc?id=16gqSgqCiIQAFlZNFV_tdGQK5Q1mijc7u'\n",
    "output = 'celeba.zip'\n",
    "#gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o1zCswppyqLP"
   },
   "outputs": [],
   "source": [
    "#!unzip celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WowRtVlEyswf"
   },
   "outputs": [],
   "source": [
    "#cd celeba/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s_n5Op-4yuZO"
   },
   "outputs": [],
   "source": [
    "#cd celeba/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-NsJp8Gfyv7u"
   },
   "outputs": [],
   "source": [
    "#!rm -R img_align_celeba/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0nlCXryHyx5O"
   },
   "outputs": [],
   "source": [
    "#!unzip img_align_celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mdvcObwLJqT_"
   },
   "outputs": [],
   "source": [
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_quDKufDJuIe"
   },
   "outputs": [],
   "source": [
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEHiSO7L0ux1",
    "outputId": "689074bf-87ad-4392-bfea-4204b99efb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-Ie4w-ZoyUoz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKW8EoDfyUoz",
    "outputId": "bd84c087-7c10-4e4f-c427-94a281b25f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all train+val samples: 162770\n"
     ]
    }
   ],
   "source": [
    "BS = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "celeba_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop((148, 148)),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "    \n",
    "\n",
    "\n",
    "my_dataset = torchvision.datasets.CelebA('./celeba/',\n",
    "                                           transform=celeba_transforms,\n",
    "                                           download=False)\n",
    "all_size = len(my_dataset)\n",
    "print('all train+val samples:', all_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PeCNcCB_yUo0"
   },
   "outputs": [],
   "source": [
    "val_size = 2000\n",
    "train_size = all_size - val_size\n",
    "train_set, val_set = torch.utils.data.random_split(my_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GxYr5rW4yUo0"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BS, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "fid_loader = DataLoader(val_set, batch_size=BS, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2VN-EMCyUo0"
   },
   "source": [
    "В этой домашней работе вам предлагается повторить результаты статьи VAE+NF (https://arxiv.org/pdf/1611.05209.pdf).\n",
    "\n",
    "Основная часть домашнего задания - чтение статьи и повторение результатов, поэтому обязательно прочитайте не только ее, но и другие основные статьи про потоки того времени:\n",
    "\n",
    "1. https://arxiv.org/abs/1505.05770\n",
    "2. https://arxiv.org/abs/1605.08803\n",
    "3. https://arxiv.org/abs/1705.07057\n",
    "4. http://arxiv.org/abs/1807.03039\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0mOQTYpyUo1"
   },
   "source": [
    "### Задача 1 (0.1 балла, но если не сделаете, за всю домашку ноль):\n",
    "\n",
    "Для начала предлагаю попробовать обучить обычный VAE на Celeba до нормального качества, померить FID и запомнить для будущего сравнения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mjxr7L2syUo1"
   },
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Atpgs3OGyUo1"
   },
   "outputs": [],
   "source": [
    "from my_utils import set_seed, count_parameters\n",
    "\n",
    "set_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zSX1iqM9yUo1"
   },
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "config = {\n",
    "    'image_size': 64,\n",
    "    'batch_size': BS,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'num_epochs': 10,\n",
    "    'grad_clip_value': 5\n",
    "}\n",
    "config = DotDict(config)\n",
    "\n",
    "### NF config\n",
    "config['hid_size'] = 24\n",
    "\n",
    "### Training and Optimization config\n",
    "config['lr_start'] = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3hopghTyUo2"
   },
   "source": [
    "### WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIHBuQ4vz0T3",
    "outputId": "bc4b64d0-af03-45e9-c1e6-847ae2645f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.22)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjPORqVfyUo2",
    "outputId": "fce6b12e-4c20-4b3b-c6db-48ab79eabab4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirili4ik\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='6aa2251ef1ea5e572e6a7608c0152db29bd9a294')\n",
    "\n",
    "def wandb_start(config, run_name):\n",
    "    wandb.init(project=\"dgm-ht3\", config=config)\n",
    "    wandb.run.name = run_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Cdu4BbRyUo2"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "VAjJL20cyUo2",
    "outputId": "686e8761-1297-4642-8c1d-5049fe41e100"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"plt.figure(figsize=(30, 30))\\n\\nfor index, image_attr in enumerate(fid_loader):\\n    \\n    image = image_attr[0].to(config.device)\\n        \\n    print(int(image.min()), int(image.max()), image.size())\\n    image = image[0]\\n    if index >= 10: break\\n    plt.subplot(10, 1, index+1)\\n    plt.imshow((image.squeeze().cpu().permute(1, 2, 0) + 1) / 2)\\n    plt.axis('off')\\n\\nplt.show()\""
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.figure(figsize=(30, 30))\n",
    "\n",
    "for index, image_attr in enumerate(fid_loader):\n",
    "    \n",
    "    image = image_attr[0].to(config.device)\n",
    "        \n",
    "    print(int(image.min()), int(image.max()), image.size())\n",
    "    image = image[0]\n",
    "    if index >= 10: break\n",
    "    plt.subplot(10, 1, index+1)\n",
    "    plt.imshow((image.squeeze().cpu().permute(1, 2, 0) + 1) / 2)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIeuwuORyUo3"
   },
   "source": [
    "### FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQe1FQ2jyUo3",
    "outputId": "81445907-813f-447a-9ccb-feb3d272fe93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from inception import InceptionV3\n",
    "\n",
    "classifier = InceptionV3()\n",
    "classifier.to(config.device)\n",
    "print()\n",
    "\n",
    "from my_calculate_fid_VAE import calculate_fid as fid_VAE\n",
    "from my_calculate_fid_NF  import calculate_fid as fid_NF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uGhr2dpPduN"
   },
   "source": [
    "### VAE Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voznpStLPj4a"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'image_size': 64,\n",
    "    'batch_size': 128,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'num_epochs': 30,\n",
    "    'grad_clip_value': 1.5\n",
    "}\n",
    "config = DotDict(config)\n",
    "\n",
    "### VAE config\n",
    "config['z_size'] = 128\n",
    "\n",
    "\n",
    "### Training and Optimization config\n",
    "config['lr_start'] = 0.005\n",
    "\n",
    "wandb_start(config, 'VAE-...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apd8NnX4OAqg"
   },
   "outputs": [],
   "source": [
    "from VAE import VAE\n",
    "\n",
    "model = VAE(\n",
    "            z_size=config.z_size,\n",
    "            im_size=config.image_size,\n",
    "            device=config.device\n",
    "        ).to(config.device)\n",
    "\n",
    "wandb.watch(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr_start)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KuGrys3OjMJ"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    batch_size = recon_x.shape[0]\n",
    "    MSE = F.mse_loss(recon_x.view(batch_size,-1), x.view(batch_size, -1), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0UvxtGBOk7x"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for ep_num in range(config.num_epochs): \n",
    "    model.train()\n",
    "    train_mse, train_kld, train_loss = 0, 0, 0\n",
    "    for index, image_attr in tqdm(enumerate(train_loader)):\n",
    "\n",
    "        image = image_attr[0].to(config.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = model(image)\n",
    "        \n",
    "        mse_loss, kld_loss = loss_function(recon_batch, image, mu, logvar)\n",
    "        loss = mse_loss + kld_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({'train loss':loss.item() / len(image),\n",
    "                   'MSE':mse_loss.item() / len(image),\n",
    "                   'KL':kld_loss.item() / len(image)\n",
    "                   })\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.encoder.parameters(), config.grad_clip_value)\n",
    "        torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), config.grad_clip_value)\n",
    "\n",
    "        if (index + 1) % 500 == 0:\n",
    "            fid = fid_VAE(config, fid_loader, model, classifier)\n",
    "            wandb.log({'FID':fid})\n",
    "            model.eval()\n",
    "\n",
    "            for ind, image_attr in enumerate(val_loader):  # batch = 1\n",
    "                if ind >= 10: break\n",
    "                image = image_attr[0].to(config.device)\n",
    "\n",
    "                fake_image, _, _ = model(image)\n",
    "\n",
    "                image = image.detach().cpu()[0]\n",
    "                fake_image = fake_image.detach().cpu()[0]\n",
    "\n",
    "                wandb.log({\"samples\": [wandb.Image((image.permute(1, 2, 0).numpy() + 1) / 2, \n",
    "                                                    caption='real'),\n",
    "                                       wandb.Image((fake_image.permute(1, 2, 0).numpy() + 1) / 2, \n",
    "                                                    caption='fake')]\n",
    "                          })\n",
    "            model.train()\n",
    "\n",
    "    print('end of epoch', ep_num)\n",
    "    torch.save(model.state_dict(), '/content/drive/MyDrive/dge3' + str(ep_num))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pz_TwYBZOm4Z"
   },
   "outputs": [],
   "source": [
    "### generation of samples\n",
    "model.eval()\n",
    "samples = model.sample(config.batch_size)\n",
    "for image in samples:\n",
    "    wandb.log({\"GENERATED\": [wandb.Image((image.detach().cpu().permute(1, 2, 0).numpy() + 1) / 2, \n",
    "                                                    caption='generated from noise')]\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jDwhnPbyUo6"
   },
   "source": [
    "### Задача 2 (0.3 балла, но если не сделаете, за всю домашку max 0.1 за прошлый пункт):\n",
    "\n",
    "После этого попробуем обучить обычный NF на Celeba до нормального качества, померить FID и запомнить для будущего сравнения\n",
    "\n",
    "В качестве потока можно использовать все что вы хотите, Coupling/Autoregressive/Linear слои, любые трансформации. \n",
    "\n",
    "Можно использовать как и сверточные потоки, так и линейные (развернув селебу в один вектор)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxvOaluAUZAc"
   },
   "source": [
    "### Real-NVP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "u3fZ_oC4PoaK",
    "outputId": "650cdd89-9aa9-4369-f51b-b90e84fdb9c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">azure-violet-33</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kirili4ik/dgm-ht3\" target=\"_blank\">https://wandb.ai/kirili4ik/dgm-ht3</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kirili4ik/dgm-ht3/runs/3l4z3k7w\" target=\"_blank\">https://wandb.ai/kirili4ik/dgm-ht3/runs/3l4z3k7w</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210322_080648-3l4z3k7w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    'image_size': 64,\n",
    "    'batch_size': 8,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'num_epochs': 30,\n",
    "    'grad_clip_value': 1.5\n",
    "}\n",
    "config = DotDict(config)\n",
    "\n",
    "### NF config\n",
    "config['hid_size'] = 30\n",
    "\n",
    "### Training and Optimization config\n",
    "config['lr_start'] = 3e-4\n",
    "\n",
    "wandb_start(config, 'NF-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5q36HPrVM8XK"
   },
   "outputs": [],
   "source": [
    "from NF import AffineHalfFlow, NormalizingFlowModel\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "# разворачиваю картинку в вектор!\n",
    "vec_size = config.image_size * config.image_size * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ogKt7EatUne3"
   },
   "outputs": [],
   "source": [
    "### creating flows\n",
    "flows = [AffineHalfFlow(dim=vec_size, \n",
    "                        parity=i%2, \n",
    "                        device=config.device) \n",
    "        for i in range(9)]\n",
    "\n",
    "### creating prior\n",
    "prior = MultivariateNormal(torch.zeros(vec_size).to(device=config.device), \n",
    "                           torch.eye(vec_size).to(device=config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohC6sKy1ecVw",
    "outputId": "249bbda3-57a1-4b9a-e99b-dc7c8cbcca8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "### creating model\n",
    "model = NormalizingFlowModel(prior, flows, device=config.device)\n",
    "wandb.watch(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr_start)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vFyjiF-a9WNL"
   },
   "outputs": [],
   "source": [
    "def evaluate(config, fid_loader, model, classifier, val_loader):\n",
    "    fid = fid_NF(config, fid_loader, model, classifier)\n",
    "    wandb.log({'FID':fid})\n",
    "\n",
    "    # deprecation\n",
    "    model.eval()\n",
    "\n",
    "    for ind, image_attr in enumerate(val_loader):  # batch = 1\n",
    "        if ind >= 10: break\n",
    "        image = image_attr[0].view(1, -1).to(config.device)   # batch=1\n",
    "\n",
    "        fake_image, _, _ = model(image)\n",
    "\n",
    "        image = image.view(1, 3,\n",
    "                          config.image_size,\n",
    "                          config.image_size).detach().cpu()[0]\n",
    "        fake_image = fake_image[-1].view(1, 3,\n",
    "                                        config.image_size,\n",
    "                                        config.image_size).detach().cpu()[0]\n",
    "\n",
    "\n",
    "        # sample\n",
    "        sampled_image = model.sample(config.batch_size)\n",
    "        sampled_image = sampled_image[-1].view(config.batch_size, 3,\n",
    "                                            config.image_size,\n",
    "                                            config.image_size).detach().cpu()[0]\n",
    "        \n",
    "        wandb.log({\"samples\": \n",
    "                   [wandb.Image((image.permute(1, 2, 0).numpy() + 1) / 2, \n",
    "                                caption='real'),\n",
    "                    wandb.Image((fake_image.permute(1, 2, 0).numpy() + 1) / 2, \n",
    "                                caption='fake')]\n",
    "                  ,\n",
    "                   \"GENERATED\":\n",
    "                   [wandb.Image((sampled_image.permute(1, 2, 0).numpy() + 1) / 2, \n",
    "                    caption='generated from noise')]\n",
    "                   })\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzQVL4Hleg10",
    "outputId": "4d91bd03-c643-42a0-cab1-73ebccf0c510"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [02:13,  1.58it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for ep_num in range(config.num_epochs): \n",
    "    model.train()\n",
    "    for index, image_attr in tqdm(enumerate(train_loader)):\n",
    "        image = image_attr[0].view(config.batch_size, -1).to(config.device)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        zs, prior_logprob, log_det = model(image)\n",
    "        logprob = prior_logprob + log_det\n",
    "        loss = -torch.mean(logprob)   # NLL\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_value)\n",
    "\n",
    "        # tracking\n",
    "        wandb.log({'NF train loss':loss.item() / vec_size})\n",
    "\n",
    "\n",
    "    evaluate(config, fid_loader, model, classifier, val_loader)\n",
    "    torch.save(model.state_dict(), '/content/drive/MyDrive/NF' + str(ep_num))\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WatxkuUSyUo6"
   },
   "source": [
    "### Задача 3 (0.6 балла):\n",
    "\n",
    "Попробуйте повторить архитектуру VAPNEV из https://arxiv.org/pdf/1611.05209.pdf. Сравните качество (FID) между тремя разными моделями\n",
    "\n",
    "Здесь вы можете использовать VAE и NF из предыдущих пунктов, необходимо только понять как они совмещаются в оригинальной статье\n",
    "\n",
    "В отчете напишите, почему по вашему мнению такой подход будет лучше (или может быть хуже) чем обычный VAE?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M99R4BsmyUo6"
   },
   "source": [
    "### Бонусная задача (0.2 балла):\n",
    "\n",
    "Найдите, реализуйте и сравните с предыдущими моделями еще один интересный способ совмещения NF и VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A-hHigeyUo6"
   },
   "source": [
    "##### Подсказки:\n",
    "\n",
    "1. Если вы учите на колабе или на наших машинках, вероятнее всего что обучение будет очень долгим на картинках 256х256. Никто не мешает уменьшить разрешение, главное чтобы было видно что генерация выучились и качество было ок\n",
    "\n",
    "2. Вы можете сделать ваш VAE/NF/VAPNEV условным, придумав как вы будете передавать в него conditional аттрибуты селебы\n",
    "\n",
    "3. Не забывайте про аугментации\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1K7eSJ36ei3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-Cdu4BbRyUo2",
    "0uGhr2dpPduN"
   ],
   "machine_shape": "hm",
   "name": "Копия блокнота \"NF.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
